================================================================================
                    ENIGMA ENGINE - HOW TO MAKE YOUR AI
================================================================================

This guide explains how to create, train, and deploy your own AI using the
Enigma Engine framework.

================================================================================
                              TABLE OF CONTENTS
================================================================================

1. QUICK START
2. UNDERSTANDING THE SYSTEM
3. PREPARING TRAINING DATA
4. TRAINING YOUR AI
5. CONNECTING YOUR AI (API/GUI/Voice)
6. MULTI-DEVICE SETUP (PC, Pi, Phone)
7. ADVANCED: TOOLS AND CAPABILITIES
8. TROUBLESHOOTING

================================================================================
                              1. QUICK START
================================================================================

STEP 1: Set up environment
--------------------------
    cd enigma_engine
    python -m venv venv --system-site-packages
    source venv/bin/activate          # Linux/Mac
    venv\Scripts\activate             # Windows
    pip install -r requirements.txt

STEP 2: Prepare training data
-----------------------------
    Create or edit: data/data.txt
    
    Format: One conversation or text sample per line
    
    Example data.txt:
    -----------------
    Hello, how are you?
    I'm doing great, thanks for asking!
    What can you help me with?
    I can help with many tasks including answering questions and conversations.
    Tell me a joke.
    Why did the programmer quit? Because he didn't get arrays!

STEP 3: Train your AI
---------------------
    python run.py --train

STEP 4: Test your AI
--------------------
    python run.py --run             # CLI mode
    python run.py --gui             # GUI mode
    python run.py --serve           # API server mode

================================================================================
                         2. UNDERSTANDING THE SYSTEM
================================================================================

ARCHITECTURE OVERVIEW
---------------------
    enigma/
    ├── core/           # Brain of the AI
    │   ├── model.py        - Neural network architecture
    │   ├── training.py     - Training logic
    │   ├── inference.py    - Text generation
    │   └── tokenizer.py    - Text to numbers conversion
    │
    ├── memory/         # AI's memory
    │   ├── manager.py      - Conversation storage
    │   ├── memory_db.py    - SQLite database
    │   └── vector_utils.py - Semantic search
    │
    ├── comms/          # Communication
    │   ├── api_server.py   - REST API (Flask)
    │   ├── mobile_api.py   - Phone app API
    │   └── network.py      - Multi-device sync
    │
    ├── tools/          # AI capabilities (16 tools)
    │   ├── web_tools.py    - Web browsing
    │   ├── file_tools.py   - File management
    │   ├── vision.py       - Screen reading
    │   └── robot_tools.py  - Robot control
    │
    ├── voice/          # Speech
    │   ├── tts_simple.py   - Text to Speech
    │   └── stt_simple.py   - Speech to Text
    │
    └── avatar/         # Visual representation
        └── controller.py   - Avatar control

MODEL SIZES
-----------
    tiny   - 9M parameters   (Raspberry Pi, phones)
    small  - 21M parameters  (Low-end PC)
    medium - 50M parameters  (Mid-range PC)
    large  - 110M parameters (Gaming PC, 4GB+ GPU)
    xl     - 350M parameters (8GB+ GPU)
    xxl    - 790M parameters (16GB+ GPU)

================================================================================
                         3. PREPARING TRAINING DATA
================================================================================

DATA FILE LOCATION
------------------
    data/data.txt

DATA FORMAT OPTIONS
-------------------

Option A: Simple text (one entry per line)
------------------------------------------
    Hello there!
    How are you today?
    I'm an AI assistant created to help.
    What would you like to know?

Option B: Conversation pairs
----------------------------
    User: Hello
    AI: Hello! How can I help you today?
    User: What's the weather like?
    AI: I don't have access to real-time weather data, but I can help you find a weather website!

Option C: Structured data (JSON)
--------------------------------
    Create: data/conversations.json
    
    [
        {
            "input": "What is Python?",
            "output": "Python is a programming language known for its simplicity."
        },
        {
            "input": "How do I learn coding?",
            "output": "Start with basics, practice daily, and build projects!"
        }
    ]

GOOD DATA CHARACTERISTICS
-------------------------
    [x] Diverse topics
    [x] Proper grammar and spelling
    [x] Consistent tone and style
    [x] Question-answer pairs work well
    [x] 10,000+ lines recommended for decent results
    [x] 100,000+ lines for good results

WHERE TO GET DATA
-----------------
    - Your own conversations
    - Public domain books (Project Gutenberg)
    - Wikipedia dumps
    - Reddit comment datasets
    - Customer service logs (anonymized)
    - Write your own Q&A pairs

================================================================================
                           4. TRAINING YOUR AI
================================================================================

BASIC TRAINING
--------------
    # Train with defaults
    python run.py --train
    
    # Force retrain (overwrites existing model)
    python -c "from enigma.core.training import train_model; train_model(force=True)"

TRAINING WITH MODEL REGISTRY
----------------------------
    # Create a named model
    python -c "
    from enigma.core.model_registry import model_registry
    model_registry.create_model('my_assistant', 'small', {
        'description': 'My personal assistant AI'
    })
    "
    
    # Train that specific model
    python -c "
    from enigma.core.trainer import ModelTrainer
    trainer = ModelTrainer()
    trainer.train_model('my_assistant', 'data/data.txt', epochs=10)
    "

TRAINING PARAMETERS
-------------------
    epochs      - Number of training cycles (default: 10)
    batch_size  - Samples per batch (default: 32)
    lr          - Learning rate (default: 0.001)
    
    More epochs = better learning but longer time
    Smaller batch = less memory needed
    Lower lr = more stable but slower learning

MONITORING TRAINING
-------------------
    Watch for:
    - Loss decreasing over epochs (good)
    - Loss not changing (increase lr or check data)
    - Loss going up (decrease lr)
    
    Good training looks like:
        Epoch 1: loss = 4.2
        Epoch 2: loss = 3.1
        Epoch 3: loss = 2.4
        ...
        Epoch 10: loss = 0.8

================================================================================
                    5. CONNECTING YOUR AI
================================================================================

METHOD 1: Command Line Interface
--------------------------------
    python run.py --run
    
    Type messages, get responses, Ctrl+C to exit.

METHOD 2: Graphical User Interface (GUI)
----------------------------------------
    python run.py --gui
    
    Features:
    - Chat tab: Talk to AI
    - Logbook tab: View conversation history
    - Training tab: Train new models
    - Avatar tab: Control AI avatar

METHOD 3: REST API Server
-------------------------
    # Start server
    python run.py --serve
    
    # Server runs at http://127.0.0.1:5000
    
    # Test with curl:
    curl -X POST http://127.0.0.1:5000/generate \
         -H "Content-Type: application/json" \
         -d '{"prompt": "Hello, who are you?"}'
    
    # API Endpoints:
    POST /generate          - Generate text
         {"prompt": "...", "max_gen": 50, "temperature": 0.7}
    
    GET  /health            - Check server status
    GET  /models            - List available models
    POST /model/select      - Switch model
         {"name": "model_name"}

METHOD 4: Voice Interface
-------------------------
    # In Python:
    from enigma.voice.stt_simple import listen_for_speech
    from enigma.voice.tts_simple import speak
    from enigma.core.inference import generate
    
    text = listen_for_speech()      # Listen
    response = generate(text)        # Think
    speak(response)                  # Speak

METHOD 5: Mobile App (via API)
------------------------------
    # Start mobile API server
    python -c "
    from enigma.comms.mobile_api import create_mobile_api
    app = create_mobile_api()
    app.run(host='0.0.0.0', port=5000)
    "
    
    # Connect from phone using IP address
    # Example: http://192.168.1.100:5000

================================================================================
                     6. MULTI-DEVICE SETUP
================================================================================

SCENARIO: Pi as server, PC as trainer, Phone as client
------------------------------------------------------

On Raspberry Pi (Server):
-------------------------
    # Start API server
    python run.py --serve
    
    # Or start mobile API
    python -c "
    from enigma.comms.mobile_api import create_mobile_api
    app = create_mobile_api()
    app.run(host='0.0.0.0', port=5000)
    "

On PC (Trainer/Client):
-----------------------
    # Train large models on PC
    python run.py --train
    
    # Connect to Pi remotely
    from enigma.comms.remote_client import RemoteEnigmaClient
    client = RemoteEnigmaClient('http://PI_IP:5000')
    response = client.generate("Hello!")

On Phone (Client):
------------------
    # Use mobile browser or custom app
    # Connect to: http://PI_IP:5000
    
    # Web interface available at:
    # http://PI_IP:5000/web

NETWORK DISCOVERY
-----------------
    # Auto-discover other Enigma devices
    from enigma.comms.discovery import DeviceDiscovery
    
    discovery = DeviceDiscovery()
    discovery.start()
    devices = discovery.get_devices()
    print(f"Found devices: {devices}")

MEMORY SYNC
-----------
    # Sync conversations across devices
    from enigma.comms.memory_sync import MemorySync
    
    sync = MemorySync()
    sync.add_peer('http://OTHER_DEVICE:5000')
    sync.sync_all()

================================================================================
                      7. ADVANCED: TOOLS AND CAPABILITIES
================================================================================

The AI has 16 built-in tools:

WEB TOOLS
---------
    web_search      - Search the internet
    web_fetch       - Get webpage content
    web_scrape      - Extract data from websites
    web_download    - Download files

FILE TOOLS
----------
    file_read       - Read file contents
    file_write      - Write to files
    file_list       - List directory contents
    file_search     - Find files

DOCUMENT TOOLS
--------------
    doc_summarize   - Summarize documents
    doc_extract     - Extract information
    doc_convert     - Convert formats
    doc_analyze     - Analyze documents

SYSTEM TOOLS
------------
    sys_info        - Get system information
    sys_command     - Run system commands
    sys_monitor     - Monitor resources
    sys_notify      - Send notifications

VISION TOOLS
------------
    screen_capture  - Screenshot
    screen_read     - OCR (read text from screen)
    find_on_screen  - Find elements

ROBOT TOOLS (for physical robots)
---------------------------------
    robot_move      - Move robot
    robot_sensor    - Read sensors
    robot_gripper   - Control gripper
    robot_status    - Get robot status

ENABLING TOOLS
--------------
    # In your code:
    from enigma.tools.tool_registry import tool_registry
    
    # Get available tools
    tools = tool_registry.list_tools()
    
    # Execute a tool
    result = tool_registry.execute('web_search', {'query': 'Python tutorials'})

================================================================================
                         8. TROUBLESHOOTING
================================================================================

PROBLEM: "No module named 'torch'"
----------------------------------
    pip install torch torchvision torchaudio
    
    # For Raspberry Pi:
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

PROBLEM: "CUDA out of memory"
-----------------------------
    - Use smaller batch size
    - Use smaller model size
    - Free up GPU memory (close other apps)

PROBLEM: "Model produces garbage"
---------------------------------
    - Need more training data
    - Train for more epochs
    - Check data quality (no corruption)

PROBLEM: "Training is slow"
---------------------------
    - Use GPU if available
    - Reduce model size
    - Use smaller batch size
    - On Pi: use 'tiny' or 'small' model only

PROBLEM: "API not accessible from other devices"
------------------------------------------------
    - Use host='0.0.0.0' instead of '127.0.0.1'
    - Check firewall settings
    - Verify IP address

PROBLEM: "Voice not working"
----------------------------
    # Install dependencies:
    sudo apt install espeak portaudio19-dev
    pip install pyttsx3 SpeechRecognition pyaudio

PROBLEM: "GUI not starting"
---------------------------
    # Install PyQt5:
    sudo apt install python3-pyqt5
    # Or: pip install PyQt5

================================================================================
                              EXAMPLES
================================================================================

EXAMPLE 1: Create a simple chatbot
----------------------------------
    # 1. Create training data
    echo "Hello!" > data/data.txt
    echo "Hi there! How can I help?" >> data/data.txt
    echo "What's your name?" >> data/data.txt
    echo "I'm Enigma, your AI assistant." >> data/data.txt
    
    # 2. Train
    python run.py --train
    
    # 3. Chat
    python run.py --run

EXAMPLE 2: Create a specialized assistant
-----------------------------------------
    # 1. Prepare domain-specific data
    # Example: cooking assistant
    # data/data.txt:
    # How do I make pasta?
    # Boil water, add pasta, cook for 8-10 minutes until al dente.
    # What's a good pizza dough recipe?
    # Mix 500g flour, 7g yeast, 325ml water, knead 10 min, rise 1 hour.
    
    # 2. Create named model
    python -c "
    from enigma.core.model_registry import model_registry
    model_registry.create_model('cooking_ai', 'small', {
        'description': 'Cooking assistant'
    })
    "
    
    # 3. Train
    python -c "
    from enigma.core.trainer import ModelTrainer
    trainer = ModelTrainer()
    trainer.train_model('cooking_ai', 'data/data.txt', epochs=20)
    "

EXAMPLE 3: Multi-device setup
-----------------------------
    # On Pi (server):
    python run.py --serve
    
    # On PC (client):
    python -c "
    from enigma.comms.remote_client import RemoteEnigmaClient
    client = RemoteEnigmaClient('http://192.168.1.100:5000')
    print(client.generate('Hello!'))
    "

================================================================================
                           TIPS FOR BEST RESULTS
================================================================================

1. DATA IS KING
   - More data = better AI
   - Quality matters more than quantity
   - Clean, well-formatted data works best

2. START SMALL
   - Begin with 'tiny' or 'small' model
   - Scale up once working

3. ITERATE
   - Train, test, improve data, repeat
   - Keep notes on what works

4. MONITOR RESOURCES
   - Watch RAM and CPU usage
   - Use appropriate model size for hardware

5. BACKUP OFTEN
   - Save working models
   - Keep training data safe

================================================================================
                           QUICK REFERENCE
================================================================================

Commands:
    python run.py --train           Train model
    python run.py --run             CLI chat
    python run.py --gui             GUI mode
    python run.py --serve           API server
    python test_system.py           Run tests

Files:
    data/data.txt                   Training data
    models/                         Saved models
    data/conversations/             Chat history
    config.json                     Settings

API Endpoint:
    POST http://127.0.0.1:5000/generate
    {"prompt": "Your message here"}

================================================================================
              Created for Enigma Engine - Your Personal AI Framework
================================================================================
